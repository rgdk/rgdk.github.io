{"name":"Rgdk.GitHub.io","tagline":"","body":"---\r\ntitle: \"Creating a Prediction Model for Exercise Style Using Accelerometric Data\"\r\ndate: \"Thursday, February 19, 2015\"\r\noutput: html_document\r\n---\r\n\r\n##Introduction\r\nThe following analysis is based on data from the 2013 Human Activity Recognition study by Wallace, Velloso and Fuks, **\"Qualitative Activity Recognition of Weight Lifting Exercises\"**. In it, the researchers record accelometric data from six subjects performing repetitions of the Unilateral Dumbbell Biceps Curl exercise. Each set of repetitions was done in five different ways. These are (as outlined in their paper):\r\n\r\n* Exactly according to the specification (Class A) \r\n* Throwing the elbows to the front (Class B)\r\n* Lifting the dumbbell only halfway (Class C) \r\n* Lowering the dumbbell only halfway (Class D) \r\n* Throwing the hips to the front (Class E)\r\n\r\nRead more at: http://groupware.les.inf.puc-rio.br/har#ixzz3SNZVfYmr\r\n\r\nThe present paper utlises this data to identify a suitable model to be used to predict the manner in which the exercise was carried out (classes A-E), which is stored in the variable 'classe'.\r\n\r\n##Data Preparation\r\n\r\nFirst install the required libraries that will be referenced during the analysis.\r\n```{r}\r\nsuppressWarnings(library(caret))\r\nsuppressWarnings(library(e1071))\r\nsuppressWarnings(library(corrplot))\r\nsuppressWarnings(library(survival))\r\n```\r\n\r\nNext retrieve the data sets - note that the non-readable strings found in the data set are set to Null by the read.csv() function.\r\n```{r}\r\nsetwd(\"C:/Training/DataScienceJHU/PracticalMachineLearning/Project\")\r\ntesting <- read.csv(\"pml-testing.csv\", stringsAsFactors=TRUE, na.strings=c(\"NA\",\"\",\"#DIV/0!\"))\r\ntraining <- read.csv(\"pml-training.csv\", stringsAsFactors=TRUE, na.strings=c(\"NA\",\"\",\"#DIV/0!\"))\r\n```\r\n\r\nDisplay the numbers of samples and variables for both the training and test data sets\r\n```{r}\r\ndim(training)\r\ndim(testing)\r\n```\r\n\r\nRemove the null-only columns from the data set\r\n```{r}\r\nnon_null_cols <- names(training)[apply(X=training, MARGIN=2, FUN=function(x) !sum(is.na(x[1])))]\r\ntrainingSubset <- training[,non_null_cols]\r\ndim(trainingSubset)\r\n```\r\n\r\n100 variables have now been discarded, leaving the following 60 contenders.\r\n```{r}\r\nnames(trainingSubset)\r\n```\r\n\r\nWe notice that some of the remaining variables are non-measurement data columns. These are now removed.\r\n```{r}\r\nmeasure_cols <- names(trainingSubset)[!(names(trainingSubset) %in% \r\n                                          c(\"X\",\r\n                                            \"user_name\",\r\n                                            \"raw_timestamp_part_1\",\r\n                                            \"raw_timestamp_part_2\",\r\n                                            \"cvtd_timestamp\",\r\n                                            \"new_window\",\r\n                                            \"num_window\"))]\r\n\r\ntrainingSubset <- trainingSubset[,names(trainingSubset) %in% measure_cols]\r\n```\r\n\r\nDetermine if there are near zero covariates amonst the remaining variables.\r\n```{r}\r\nnzv <- nearZeroVar(trainingSubset, saveMetrics=TRUE)\r\nnzv\r\n```\r\n\r\nIt appears that there are none to be removed. \r\n\r\nDetermine which variables remain \r\n```{r}\r\nnames(trainingSubset)\r\n```\r\n\r\nLook at the distribution of values in the classe variable that is to be predicted. \r\n```{r}\r\ntable(trainingSubset$classe)\r\n```\r\n\r\nIt appears that there are more in class A than any other class.\r\n\r\nDetermine any near-perfectly correlated variables which we define as those with a greater correlation than +/-0.8\r\n```{r}\r\ncorrelValues <- abs(cor(trainingSubset[,-53]))\r\ndiag(correlValues) <- 0\r\n```\r\n\r\nPlot the correlations\r\n```{r}\r\ncorrplot(correlValues, method=\"square\", type = \"lower\", tl.cex=0.8)\r\n```\r\n\r\nDetermine the column indices of the variables with high correlation and display them\r\n```{r}\r\nhighCorr <- findCorrelation(correlValues[,-53], cutoff = .80)     # high correlation\r\nnames(trainingSubset[,highCorr])\r\n```\r\n\r\nRemove these highly correlated variables and display the remaining variables\r\n```{r}\r\ntrainingSubset<-trainingSubset[,-highCorr]    \r\nlength(names(trainingSubset))\r\n```\r\n\r\nNow divide and train the training data.\r\n```{r}\r\nset.seed(56789)\r\ninTrain = createDataPartition(y=trainingSubset$classe, p=0.75, list=FALSE)\r\ntraindata = trainingSubset[ inTrain,]\r\ntestdata =  trainingSubset[-inTrain,]\r\n```\r\n\r\n##Setup the prediction model\r\n\r\nWe will evaluate three different models before settling on a final choice.\r\n\r\nFirst we have elected to use a Linear Discriminant Analysis (LDA) model with cross-validation involving 3 times resampling\r\n```{r}\r\ntrainCtrl <- trainControl(method = \"cv\", number=3)\r\nLDAmodelFit <- train(classe ~ ., method=\"lda\", data=traindata, trControl=trainCtrl)\r\nLDAmodelFit\r\n```\r\n\r\nTo see how successful the LDA model is we run a confusion matrix.\r\n```{r}\r\nLDAConfusionmatrix <- confusionMatrix(testdata$classe,predict(LDAmodelFit,testdata))\r\nLDAConfusionmatrix\r\n```\r\nThe Accuracy of the model appears to be 64.1%.\r\n\r\nNext we have elected to use a Generalised Boosted Regression (GBM) model with cross-validation involving 3 times resampling\r\n```{r}\r\ntrainCtrl <- trainControl(method = \"cv\", number=3)\r\nGBMmodelFit <- train(classe ~ ., method=\"gbm\", data=traindata, trControl=trainCtrl, verbose = FALSE)\r\nGBMmodelFit\r\n```\r\n\r\nTo see how successful the GBM model is we run a confusion matrix.\r\n```{r}\r\nGBMConfusionmatrix <- confusionMatrix(testdata$classe,predict(GBMmodelFit,testdata))\r\nGBMConfusionmatrix\r\n```\r\nThe Accuracy of the model appears to be 94.9%.\r\n\r\nLets see what the optimal model parameters were.\r\n```{r}\r\nGBMmodelFit\r\n```\r\n\r\nThese results are reflected in the following plot.\r\n```{r}\r\nplot(GBMmodelFit)\r\n```\r\n\r\nIt appears that greater accuracy is achieved in the gbm model with more trees and greater depth of the analysis. An even better result may be had by changing either of these parameters.  \r\n\r\nFinally we have elected to use a Random Forest (RF) model with cross-validation involving 3 times resampling\r\n```{r}\r\ntrainCtrl <- trainControl(method = \"cv\", number=3)\r\nRFmodelFit <- train(classe ~ ., method=\"rf\", data=traindata, trControl=trainCtrl, importance=TRUE)\r\nRFmodelFit\r\n```\r\n\r\nTo see how successful the RF model is we run a confusion matrix.\r\n```{r}\r\nRFConfusionmatrix <- confusionMatrix(testdata$classe,predict(RFmodelFit,testdata))\r\nRFConfusionmatrix\r\n```\r\n\r\nLets see what the estimated overall error rate is:\r\n```{r}\r\nRFmodelFit$finalModel\r\n```\r\n\r\nIt can be seen that the Out Of Bag estimate of error rate is 0.75%\r\nThe accuracy is: 99.2% which is reflected in the following plot.\r\n\r\n```{r}\r\nplot(RFmodelFit)\r\n```\r\n\r\nIt appears that the RF model is extremely accurate with over 99% accuracy across each classe grouping. This was closely followed by the gbm boosting model at just under 95% accuracy.The LDA model followed way behind with only a 64% accuracy.\r\n\r\n##In Conclusion\r\n\r\nSo what are the answers given by each of the models?\r\n\r\nLinear Discriminant Analysis:\r\n```{r}\r\nLDAtest_answers <- predict(LDAmodelFit, testingSubset[,-41])\r\n```\r\n\r\nGBM:\r\n```{r}\r\nGBMtest_answers <- predict(GBMmodelFit, testingSubset[,-41])\r\n```\r\n\r\nRandom Forest:\r\n```{r}\r\nRFtest_answers <- predict(RFmodelFit, testingSubset[,-41])\r\n```\r\n\r\nLet's look at the results of each test when the prediction models are applied:\r\n```{r}\r\nanswers <- as.data.frame(matrix(seq(NA), nrow=3, ncol=21))\r\n\r\nnames(answers)<-c('Test Name',\r\n                  'Test 1','Test 2','Test 3','Test 4','Test 5',\r\n                  'Test 6','Test 7','Test 8','Test 9','Test 10',\r\n                  'Test 11','Test 12','Test 13','Test 14','Test 15',\r\n                  'Test 16','Test 17','Test 18','Test 19','Test 20')\r\n\r\nanswers[1,1] <- 'LDA'\r\nanswers[2,1] <- 'GMB'\r\nanswers[3,1] <- 'RF'\r\n\r\nanswers[1,2:21] <- as.factor(LDAtest_answers)\r\nanswers[2,2:21] <- as.factor(GBMtest_answers)\r\nanswers[3,2:21] <- as.factor(RFtest_answers)\r\n\r\nanswers\r\n```\r\n\r\nFrom these results it appears that the minor difference in accuracy between the RF and GMB models made no difference in the outcome when applied to the test set. The LDA model, however, produced vastly different results.\r\n\r\nOn the basis of accuracy alone, the present analysis has decided to choose the Random Forest model.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}